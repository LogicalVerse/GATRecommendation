{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9544366,"sourceType":"datasetVersion","datasetId":5814556}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch torchvision torchaudio torch-geometric pandas\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T10:06:11.775607Z","iopub.execute_input":"2024-10-04T10:06:11.776163Z","iopub.status.idle":"2024-10-04T10:06:29.038807Z","shell.execute_reply.started":"2024-10-04T10:06:11.776118Z","shell.execute_reply":"2024-10-04T10:06:29.037250Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0+cpu)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.4.0+cpu)\nCollecting torch-geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.9.5)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (5.9.3)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (4.66.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2024.8.30)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.6.1\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import zipfile\nimport os\nimport urllib.request\n\n# Download the dataset\nurl = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\nfilename = \"ml-latest-small.zip\"\nurllib.request.urlretrieve(url, filename)\n\n# Extract the dataset\nwith zipfile.ZipFile(filename, 'r') as zip_ref:\n    zip_ref.extractall(\"ml-latest-small\")\n\n# Load the CSV file\n# df = pd.read_csv('/kaggle/working/ml-latest-small/ml-latest-small/ratings.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-04T10:05:34.917252Z","iopub.execute_input":"2024-10-04T10:05:34.917777Z","iopub.status.idle":"2024-10-04T10:05:35.711546Z","shell.execute_reply.started":"2024-10-04T10:05:34.917728Z","shell.execute_reply":"2024-10-04T10:05:35.710226Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/working/ml-latest-small/ml-latest-small/ratings.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-04T10:05:50.775901Z","iopub.execute_input":"2024-10-04T10:05:50.776407Z","iopub.status.idle":"2024-10-04T10:05:50.867703Z","shell.execute_reply.started":"2024-10-04T10:05:50.776365Z","shell.execute_reply":"2024-10-04T10:05:50.866192Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T10:05:52.654187Z","iopub.execute_input":"2024-10-04T10:05:52.654703Z","iopub.status.idle":"2024-10-04T10:05:52.681070Z","shell.execute_reply.started":"2024-10-04T10:05:52.654658Z","shell.execute_reply":"2024-10-04T10:05:52.679718Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   userId  movieId  rating  timestamp\n0       1        1     4.0  964982703\n1       1        3     4.0  964981247\n2       1        6     4.0  964982224\n3       1       47     5.0  964983815\n4       1       50     5.0  964982931","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>964982703</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4.0</td>\n      <td>964981247</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6</td>\n      <td>4.0</td>\n      <td>964982224</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>47</td>\n      <td>5.0</td>\n      <td>964983815</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>50</td>\n      <td>5.0</td>\n      <td>964982931</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import GATConv\n\n# Load Movielens dataset (ratings data)\n# url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n# df = pd.read_csv('/kaggle/input/ml-latest-small/ratings.csv')\n\n# Extract necessary columns: userId, movieId, rating\ndf = df[['userId', 'movieId', 'rating']]\n\n# Map users and movies to consecutive node IDs\nuser_mapping = {id: i for i, id in enumerate(df['userId'].unique())}\nmovie_mapping = {id: i + len(user_mapping) for i, id in enumerate(df['movieId'].unique())}\n\ndf['userId'] = df['userId'].map(user_mapping)\ndf['movieId'] = df['movieId'].map(movie_mapping)\n\n# Create edge index (graph structure) and edge features (ratings)\nedge_index = torch.tensor([df['userId'].values, df['movieId'].values], dtype=torch.long)\nedge_attr = torch.tensor(df['rating'].values, dtype=torch.float)\n\n# Define the number of user nodes and movie nodes\nnum_users = len(user_mapping)\nnum_movies = len(movie_mapping)\nnum_nodes = num_users + num_movies\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T10:08:02.781563Z","iopub.execute_input":"2024-10-04T10:08:02.782152Z","iopub.status.idle":"2024-10-04T10:08:06.366326Z","shell.execute_reply.started":"2024-10-04T10:08:02.782106Z","shell.execute_reply":"2024-10-04T10:08:06.365137Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/208465854.py:21: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n  edge_index = torch.tensor([df['userId'].values, df['movieId'].values], dtype=torch.long)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import torch.nn.functional as F\nfrom torch_geometric.nn import GATConv\n\nclass GATRecommendation(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, heads=1, dropout=0.3):\n        super(GATRecommendation, self).__init__()\n        \n        # First GAT layer\n        self.gat1 = GATConv(in_channels, out_channels, heads=heads, dropout=dropout)\n        \n        # Second GAT layer\n        self.gat2 = GATConv(out_channels * heads, out_channels, heads=heads, concat=False, dropout=dropout)\n\n        # Classifier for user-movie interaction prediction\n        self.classifier = torch.nn.Linear(out_channels, 1)\n        \n    def forward(self, x, edge_index, edge_attr):\n        # Strong and weak ties (attention coefficients depend on edge_attr, i.e., ratings)\n        x = F.elu(self.gat1(x, edge_index, edge_attr=edge_attr))\n        x = self.gat2(x, edge_index, edge_attr=edge_attr)\n        \n        return x\n    \n    def predict(self, x):\n        return torch.sigmoid(self.classifier(x))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T10:08:16.681283Z","iopub.execute_input":"2024-10-04T10:08:16.681973Z","iopub.status.idle":"2024-10-04T10:08:16.693654Z","shell.execute_reply.started":"2024-10-04T10:08:16.681903Z","shell.execute_reply":"2024-10-04T10:08:16.692156Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import torch\nimport torch_geometric\nfrom torch_geometric.data import Data\n\n# Assuming you have 610 users and 9724 movies\nnum_users = 610\nnum_movies = 9724\ntotal_nodes = num_users + num_movies\n\n# Initialize node features (one-hot encoding)\nuser_features = torch.eye(num_users)  # Shape: [610, 610]\nmovie_features = torch.eye(num_movies)  # Shape: [9724, 9724]\n\n# Pad user features to match movie feature dimension and vice versa\nuser_features_padded = torch.cat([user_features, torch.zeros(num_users, num_movies)], dim=1)  # Shape: [610, 9724 + 610]\nmovie_features_padded = torch.cat([torch.zeros(num_movies, num_users), movie_features], dim=1)  # Shape: [9724, 9724 + 610]\n\n# Combine user and movie features into a single feature matrix\nx = torch.cat([user_features_padded, movie_features_padded], dim=0)  # Shape: [610 + 9724, 610 + 9724]\n\n# Print the size of the combined feature matrix\nprint(x.shape)  # Should print: torch.Size([10334, 10334])\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T10:08:20.194371Z","iopub.execute_input":"2024-10-04T10:08:20.194897Z","iopub.status.idle":"2024-10-04T10:08:21.110038Z","shell.execute_reply.started":"2024-10-04T10:08:20.194850Z","shell.execute_reply":"2024-10-04T10:08:21.108817Z"},"trusted":true},"outputs":[{"name":"stdout","text":"torch.Size([10334, 10334])\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Assuming edge_index and edge_attr are already defined (they represent the graph structure)\ndata = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n\n# Check the data object\nprint(data)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T10:08:23.829780Z","iopub.execute_input":"2024-10-04T10:08:23.831073Z","iopub.status.idle":"2024-10-04T10:08:23.840984Z","shell.execute_reply.started":"2024-10-04T10:08:23.831023Z","shell.execute_reply":"2024-10-04T10:08:23.839557Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Data(x=[10334, 10334], edge_index=[2, 100836], edge_attr=[100836])\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import torch.optim as optim\n\n# Define the model, optimizer, and loss function\nmodel = GATRecommendation(in_channels=data.num_features, out_channels=64, heads=4, dropout=0.3)\noptimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\ncriterion = torch.nn.BCELoss()\n\n# Split data into training and testing sets (80-20 split)\ntrain_mask = torch.rand(data.num_edges) < 0.8\ntest_mask = ~train_mask\n\n# Helper function to get edge predictions\ndef get_edge_predictions(node_embeddings, edge_index):\n    # Get source and target node embeddings for each edge\n    source_embeddings = node_embeddings[edge_index[0]]\n    target_embeddings = node_embeddings[edge_index[1]]\n    \n    # Compute edge predictions (e.g., inner product or similarity between node embeddings)\n    edge_predictions = torch.sigmoid((source_embeddings * target_embeddings).sum(dim=1))\n    \n    return edge_predictions\n\n# Training the GAT model\ndef train():\n    model.train()\n    optimizer.zero_grad()\n\n    # Forward pass: Get node embeddings from the model\n    out = model(data.x, data.edge_index, data.edge_attr)\n\n    # Get edge predictions for the training set\n    train_edge_predictions = get_edge_predictions(out, data.edge_index[:, train_mask])\n\n    # Ensure that edge attributes are between 0 and 1 (if binary)\n    data.edge_attr = torch.clamp(data.edge_attr, 0, 1)\n\n    # Compute the loss on the training edges\n    loss = criterion(train_edge_predictions, data.edge_attr[train_mask].float())\n\n    # Backward pass and optimization\n    loss.backward()\n    optimizer.step()\n\n    return loss.item()\n\n\n# Testing the GAT model\ndef test():\n    model.eval()\n    with torch.no_grad():\n        # Get node embeddings from the model\n        out = model(data.x, data.edge_index, data.edge_attr)\n        \n        # Get edge predictions for the test set\n        test_edge_predictions = get_edge_predictions(out, data.edge_index[:, test_mask])\n        \n        # Compute the loss on the test edges (no unsqueeze needed here)\n        loss = criterion(test_edge_predictions, data.edge_attr[test_mask].float())\n        \n    return loss.item()\n\n# Training loop\nfor epoch in range(200):\n    loss = train()\n    if epoch % 10 == 0:\n        test_loss = test()\n        print(f'Epoch {epoch}, Loss: {loss}, Test Loss: {test_loss}')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T10:08:26.250091Z","iopub.execute_input":"2024-10-04T10:08:26.250672Z","iopub.status.idle":"2024-10-04T10:15:24.816007Z","shell.execute_reply.started":"2024-10-04T10:08:26.250625Z","shell.execute_reply":"2024-10-04T10:15:24.814573Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 0, Loss: 0.6929823160171509, Test Loss: 0.690059244632721\nEpoch 10, Loss: 0.36320239305496216, Test Loss: 0.5957578420639038\nEpoch 20, Loss: 0.6578162908554077, Test Loss: 0.6523407697677612\nEpoch 30, Loss: 0.5867574214935303, Test Loss: 0.6105227470397949\nEpoch 40, Loss: 0.1783255785703659, Test Loss: 0.11204014718532562\nEpoch 50, Loss: 0.048870399594306946, Test Loss: 0.03552335500717163\nEpoch 60, Loss: 0.040481775999069214, Test Loss: 0.03467473387718201\nEpoch 70, Loss: 0.04163932055234909, Test Loss: 0.03444087132811546\nEpoch 80, Loss: 0.040608689188957214, Test Loss: 0.03381260111927986\nEpoch 90, Loss: 0.03956958279013634, Test Loss: 0.033914897590875626\nEpoch 100, Loss: 0.03966621309518814, Test Loss: 0.033706068992614746\nEpoch 110, Loss: 0.03881607577204704, Test Loss: 0.033678848296403885\nEpoch 120, Loss: 0.0375114269554615, Test Loss: 0.03372076153755188\nEpoch 130, Loss: 0.03825031593441963, Test Loss: 0.0336945503950119\nEpoch 140, Loss: 0.038477249443531036, Test Loss: 0.0338282473385334\nEpoch 150, Loss: 0.03937401995062828, Test Loss: 0.03405819088220596\nEpoch 160, Loss: 0.03776876628398895, Test Loss: 0.034132689237594604\nEpoch 170, Loss: 0.038547173142433167, Test Loss: 0.034299902617931366\nEpoch 180, Loss: 0.0373203307390213, Test Loss: 0.034384727478027344\nEpoch 190, Loss: 0.03818034380674362, Test Loss: 0.03441702201962471\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}